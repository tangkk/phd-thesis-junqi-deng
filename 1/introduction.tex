
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
\chapter{Introduction}\label{cp:intro}

% ----------------------------------------------------------------------
%: ----------------------- introduction content ----------------------- 
% ----------------------------------------------------------------------



%: ----------------------- HELP: latex document organisation
% the commands below help you to subdivide and organise your thesis
%    \chapter{}       = level 1, top level
%    \section{}       = level 2
%    \subsection{}    = level 3
%    \subsubsection{} = level 4
% note that everything after the percentage sign is hidden from output

This chapter introduces automatic chord estimation (ACE) by defining the problem in Section~\ref{sec:1-problemdef} and motivating it in Section~\ref{sec:1-moti}. Then the thesis structure will be elaborated in Section~\ref{sec:1-outline}, followed by the thesis contributions and the author's list of publications in Section~\ref{sec:1-contribution}.

\section{Problem Definition} \label{sec:1-problemdef}
Automatic chord estimation, or ACE, within the context of this thesis, refers to a task that \textbf{estimates, recognizes, or transcribes the segmented chord sequence from a piece of audio under equal-temperament tonal music constraint} (see Chapter~\ref{cp:background} for more definitions on these musical terms). In this definition, the verbs ``estimate'', ``recognize'' or ``transcribe'' all refer to the same process. This process analyzes the input audio, uncovers the underlying chord progression, and segments the audio in terms of these chords. Besides, ACE also asks for the \textbf{classification of chord and non-chord (i.e., silence, natural sound, environmental noise, etc.) materials}. Figure~\ref{fig:1-acemir} illustrates ACE as a music information retrieval (MIR) task.
\begin{figure}[h]
\centering
\includegraphics[width=0.8\columnwidth]{1/figures/acemir.PNG}
\caption{ACE as an MIR task. An ACE algorithm (\textbf{retrieval}) takes the input audio (\textbf{music}), and generates a piece of segmented chord/no-chord sequence (\textbf{information}) as output.}
\label{fig:1-acemir}
\end{figure}

\section{Motivation for ACE} \label{sec:1-moti}
ACE has been one of the most important problems in MIR. The motivation for ACE research is four-fold, explained as follows:

\subsection{ACE as submodule to other tasks}
ACE could be a subproblem of other tasks such as: cover song identification \cite{bello2007audio,lee2006identifying,serra2010audio}, which makes use of chord sequences similarity; music structural segmentation \cite{bello2005robust}, where structure is cued by repetitions of chord sequences; and genre classification \cite{cheng2008automatic,perez2009genre}, where the chord sequence itself carries genre information. It could also play a critical role in problems such as: audio key detection \cite{papadopoulos2012modeling,pauwels2010integrating}, where the estimated chord sequence could be used to infer the key or key sequence;  and downbeat estimation \cite{papadopoulos2008simultaneous,mauch2010simultaneous}, where the chord boundaries and downbeats sometimes overlap.

\subsection{ACE as chord transcription engine}
For human beings, recognizing and transcribing chords from audio, especially the ability to distinguish among similar chords (e.g., $C7$, $C9$ and $C7/G$), is a way to demonstrate sophisticated musicianship. People with chord transcription abilities have developed the popular chord-lyrics websites such as UltimateGuitar \footnote{\url{ultimate-guitar.com}}, E-chords \footnote{\url{e-chords.com}} and many others \footnote{\url{polygonguitar.blogspot.hk}; \url{chords-haven.blogspot.hk}; \url{azchords.com}} alike, where the chords of millions of songs can be found. To be useful for practical purpose (e.g., song covering, rehearsal, performance, busking), those chords are often captured in great detail, with a very large vocabulary including the suspensions, extensions, inversions and alterations. The annotators try to recover every subtle flavor of the original recordings by means of the handy chord labels. Figure~\ref{fig:1-humanchord} showcases some of the human chord annotation examples from the above mentioned websites.
\begin{figure}[htb]
\centering
\includegraphics[width=1\columnwidth]{1/figures/humanchord.PNG}
\caption{Human chord annotation examples}
\label{fig:1-humanchord}
\end{figure}

However, musical sophistication cannot be easily replicated. As a result, at some point, the need for chord annotations will overwhelm the human annotation workforce. With the ever increasing music production rate \cite{globalmusicreport}, it is foreseeable that the future chord-lyrics services will increasingly rely on the ACE technologies. Consequently, a chord transcription engine powered by large vocabulary ACE (or LVACE) technology will become necessary.
%Regarding one of the ultimate goals in music informatics as building a human-like music intelligence system, LVACE is absolutely a significant part of the machine.

\subsection{ACE as part of artificial musicianship}
Human musicianship requires as least one of the four kinds of trainings: ear training, sight-reading, composition and improvisation (Figure~\ref{fig:1-musictraining}) . MIR researches mostly focus on the ``ear training'' and ``sight-reading''. The ability to transcribe ``chords'' is obviously a result of ``ear training''.
\begin{figure}[htb]
\centering
\includegraphics[width=0.6\columnwidth]{1/figures/musictraining.pdf}
\caption{Musical training v.s. language training}
\label{fig:1-musictraining}
\end{figure}

Ear training, according to the EarMasterPro \footnote{\url{http://www.earmaster.com/}} (as elaborated in Figure~\ref{fig:1-eartraining}), includes several sub-trainings. The ``identification of chords'' is one of them. Therefore, in artificial musicianship, ACE plays an important part of the artificial musical ``ear''.
\begin{figure}[htb]
\centering
\includegraphics[width=0.6\columnwidth]{1/figures/eartraining.pdf}
\caption{Ear training according to the EarMasterPro}
\label{fig:1-eartraining}
\end{figure}

\subsection{ACE inspires scientific researches on human audition and mind}
Last but not the least, ACE research, in an algorithmic level, could shed light on the working mechanism of human's perception towards musical harmony. This similar motivation is shared by many other artificial intelligent researches\cite{lecun1995convolutional,hinton1995wake}, where the explorations of algorithmic or machine learning solutions themselves inspire the scientific researches on the visual perception system within the human brain.

\section{Motivation for LVACE} %FIXME: please write a paragraph to motivate this before going to the next section
% idea:
% 1. to build more sophisticated chord transcription service;  to match human ACE performance
% 2. for ultimate artificial musicianship
Now that the motivation for ACE is clear, the motivation for LVACE could be reduced to the necessity of LV. If an ACE system does not support LV (for example, only \textit{major} and \textit{minor} chords are supported), it misses a lot of harmonic details of the original song's arrangement, thus its output will not be suitable for practical usage such as song covering, rehearsal, or busking. Furthermore, the absence of LV will make the system impossible to pass the Turing test since any human chord annotation expert is able to label chords with a large vocabulary. Therefore:
\begin{itemize}
	\item LV is necessary for a practical chord transcription service.
	\item LV is necessary for an ACE system to pass the Turing test \cite{turing1950computing}.
\end{itemize}

\section{Research Scope} \label{sec:1-scope}
\noindent
It is necessary to firstly define the scope of this study:
\begin{itemize}
	\item What types of large vocabularies will be studied?
	\item What types of music will be studied?
\end{itemize}
In Chapter~\ref{cp:background}, we will introduce several vocabularies, including the \textit{SeventhsBass} vocabulary, which is used by the current standard ACE evaluation. This is regarded as a large vocabulary, as oppose to the one only containing \textit{major} and \textit{minor} triads. The \textit{SeventhsBass} will be the main focused of this thesis.

Besides, pop and rock music will be the main focus of this thesis, because almost all ACE datasets are built around these two genres. In Chapter~\ref{cp:jazz} we try to extend it to jazz, but nevertheless, most of the discussions and conclusions in this thesis are only verified under pop and rock music.

\section{Thesis Structure} \label{sec:1-outline}
This thesis focuses on deep learning solutions to LVACE. The main contributions of this thesis can be found in Chapter~\ref{cp:ghmm},~\ref{cp:endtoend} and \ref{cp:jazz}, where Chapter~\ref{cp:ghmm} and ~\ref{cp:endtoend} are parallel sections presenting two different LVACE solutions, and Chapter~\ref{cp:jazz} takes one of them and build algorithmic music systems for jazz. Concretely:

\Hsection{Chapter~\ref{cp:intro}} is the introduction to the whole thesis. It defines the ACE problem, motivates the LVACE from different perspectives, and sketches the thesis outline and contributions.

\Hsection{Chapter~\ref{cp:background}} is the literature review. The chapter firstly provides the necessary musical fundamentals for a good understanding of ACE. Then it looks back into ACE's history and tries to come up with a storyline of different ACE modules and submodules. Finally it examines various preferences on ACE evaluations, especially the issues and arguments on LVACE evaluation and human annotation subjectivity.

\Hsection{Chapter~\ref{cp:ghmm}} describes an LVACE approach that makes hybrid use of a classical segmentation process and a deep learning based chord labeling process. The chapter explores variations and limitations of this system framework, and gives much analysis of the system behaviors under different settings.
% It addresses the concrete design of the feature extraction and pattern matching modules, where the latter is realized through three deep neural networks. 

\Hsection{Chapter~\ref{cp:endtoend}} describes an LVACE approach where the sequence segmentation and classification are all done by a single recurrent neural network. To accommodate to large vocabulary, a skewed classes oriented training scheme is used. This training scheme is shown to be very effective in improving the system's vocabulary versatility.

\Hsection{Chapter~\ref{cp:jazz}} extends the application of LVACE to jazz music. The chapter firstly introduces the musical fundamentals of jazz. Then it extends the LVACE approaches to jazz, and brings in an extra ``scale'' estimation process to enable the ``chord-scale'' estimation. Combining with two jazz improvisation interfaces, it shows how novice users can make good improvisations out of jazz backings.
%  (see Section~\ref{sec:5-jazzfund} for more details of these musical terms)

\Hsection{Chapter~\ref{cp:conclude}} concludes the thesis with suggestions to possible future directions of ACE and LVACE. At the end of this chapter we speculate on the feasibility of an LVACE system for all chords in all kinds of music.


\section{Contributions and Publications by the Author} \label{sec:1-contribution}
The major contributions of this thesis are mainly on the deep learning methods and skewed class distribution oriented techniques for LVACE. Particularly, this thesis proposes two LVACE approaches:
\begin{enumerate}
\item A hybrid classical segmentation and deep neural nets chord labeling approach;
\item A recurrent neural network sequence decoding with an even chance training scheme approach.
\end{enumerate}
There are also minor contributions in the algorithmic applications of jazz. Particularly, this thesis proposes:
\begin{enumerate}
\item A jazz chord-scale estimation system that augments the LVACE framework with a local scale tracking algorithm.
\item A fully automatic jazz improvisation process that combines the chord-scale estimation system and a note generation process.
\item Two semi-automatic jazz improvisation platforms that enable users to create melodies based on a chord-scale sequence.
\end{enumerate}
\noindent
In correspond to the thesis contributions, the author has published the following articles:
\begin{itemize}
\item Deng, J., Kwok, Y. K. Large Vocabulary Automatic Chord Estimation with an Even Chance Training Scheme, In Proceedings of the 18th International Society for Music Information Retrieval Conference, Suzhou, China, 2017
\item Deng, J., Kwok, Y. K. A Hybrid Gaussian-HMM-Deep-Learning Approach For Automatic Chord Estimation with Very Large Vocabulary, In Proceedings of the 17th International Society for Music Information Retrieval Conference, New York City, USA, 2016
\item Deng, J., Kwok, Y. K. A Chord-scale Approach to Automatic Jazz Improvisation, In Late-breaking/demo Proceedings of the 17th International Society for Music Information Retrieval Conference, New York City, USA, 2016
\item Deng, J., Kwok, Y. K., Automatic Chord Estimation on SeventhsBass Chord Vocabulary Using Deep Neural Network, In Proceedings of the 41st International Conference on Acoustics, Speech, and Signal Processing, Shanghai, China, 2016
%\item Hu, X., Deng, J., Zhao, J., Hu, W., Ngai, E. C. H., Wang, R., ... and Kwok, Y. K., SAfeDJ: A Crowd-Cloud Codesign Approach to Situation-Aware Music Delivery for Drivers. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 12(1s), 21., 2015
\item Deng, J., Lau, F. C. M., and Kwok, Y. K., ArmKeyBoard: A Mobile Keyboard Instrument Based on Chord-Scale System and Tonal Hierarchy. In Proceedings of the 40th International Computer Music Conference, Athens, Greece, 2014.
\item Deng, J., Lau, F. C. M., Ng, H. C., Kwok, Y. K., Chen, H. K., and Liu, Y. H., WIJAM: A Mobile Collaborative Improvisation Platform under Master-Players Paradigm. In Proceedings of the 14th International Conference on New Interfaces for Musical Expression, London, UK., 2014
\end{itemize}

There are currently two articles under review:
\begin{itemize}
\item Deng, J., Kwok, Y. K., Large Vocabulary Automatic Chord Estimation Using Deep Neural Nets: Design Framework, System Variations and Limitations, submitted to EURASIP Journal on Audio, Speech, and Music Processing, 2017 (under review)
\item Deng, J., Kwok, Y. K., Large Vocabulary Automatic Chord Estimation Using Bidirectional Long Short-Term Memory Recurrent Neural Network with Even Chance Training, submitted to Journal of New Music Research, 2017 (minor revision, can be accepted after one more round)
\end{itemize}



