
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
\chapter{Introduction}\label{cp:intro}

% ----------------------------------------------------------------------
%: ----------------------- introduction content ----------------------- 
% ----------------------------------------------------------------------



%: ----------------------- HELP: latex document organisation
% the commands below help you to subdivide and organise your thesis
%    \chapter{}       = level 1, top level
%    \section{}       = level 2
%    \subsection{}    = level 3
%    \subsubsection{} = level 4
% note that everything after the percentage sign is hidden from output

This chapter introduces automatic chord estimation (ACE) by defining the problem in Section~\ref{sec:1-problemdef} and motivating it in Section~\ref{sec:1-moti}. Then the thesis structure will be elaborated in Section~\ref{sec:1-outline}, followed by the thesis contributions and the author's publications in Section~\ref{sec:1-contribution}.

\section{Problem Definition} \label{sec:1-problemdef}
ACE, within the context of this thesis, refers to a task that \textbf{estimates, recognizes, or transcribes the segmented chord sequence from a piece of audio (i.e., a song or a musical instrumental) that contains such sequence under equal-temperament tonal music constraint} (see Chapter~\ref{cp:background} for more definitions of these musical terms). In this definition, the verbs ``estimate'', ``recognize'' or ``transcribe'' all refer to the same process. This process analyzes the input audio, uncovers the underlying chord progression, and segments the audio in terms of these chords. The task also asks for \textbf{classification of chord material and no-chord material (i.e., silence, natural sound, environmental noise, etc.)}, hence the algorithms that solve this task should be able to label both. Figure~\ref{fig:1-acemir} illustrates ACE as a music information retrieval (MIR) task.
\begin{figure}[h]
\centering
\includegraphics[width=0.8\columnwidth]{1/figures/acemir.PNG}
\caption{ACE as an MIR task. An ACE algorithm takes its input audio, and generates a piece of segmented chord/no-chord sequence as output.}
\label{fig:1-acemir}
\end{figure}

\section{Motivation} \label{sec:1-moti}
ACE has been one of the most important problems in MIR. The motivation of an ACE research is four-fold, expounded as follows:

\subsection{ACE as submodule to other tasks}
ACE is a subproblem in other tasks such as cover song identification \cite{bello2007audio,lee2006identifying,serra2010audio} (which makes use of the chord sequence similarity), music structural segmentation \cite{bello2005robust} (where the repetition of a chord sequence is a structural cue), and genre classification \cite{cheng2008automatic,perez2009genre} (where the chord sequence itself carries genre information). It also has a critical role in problems such as audio key detection \cite{papadopoulos2012modeling,pauwels2010integrating} and downbeat estimation \cite{papadopoulos2008simultaneous,mauch2010simultaneous}, where in the former problem the estimated chord sequence often serves as a lower level harmonic information to infer the key or key sequence, while in the latter the chord and downbeat estimation are sometimes a dual problem within one single algorithmic framework.

\subsection{ACE's own merit as chord transcription engine}
For human beings, recognizing and transcribing chords from audio, especially the ability to distinguish among similar chords (e.g., $C7$ and $C13$), is a common way to demonstrate sophisticated musicianship. People with chord transcription abilities help power the popular chords-lyrics websites such as UltimateGuitar \footnote{\url{ultimate-guitar.com}}, E-chords \footnote{\url{e-chords.com}} and many others \footnote{\url{polygonguitar.blogspot.hk; chords-haven.blogspot.hk; azchords.com}}, where the chords of millions of songs can be found. For practical use (e.g., song covering, rehearsal, performance), those chords are often captured in great details, with large vocabulary including the suspensions, extensions, inversions and even the alterations, that try to recover every subtle flavor of the original recordings by means of these handy chord representations. Figure~\ref{fig:1-humanchord} showcases some of the human chord annotation examples from the above mentioned websites.
\begin{figure}
\centering
\includegraphics[width=1\columnwidth]{1/figures/humanchord.PNG}
\caption{Human chord transcriptions from popular chords-lyrics websites}
\label{fig:1-humanchord}
\end{figure}

But such human musical sophistication is not a resource that can be easily replicated, and thus at some point the need for chord annotations will overwhelm the annotation workforce. With the ever increasing music production speed \cite{globalmusicreport}, it is foreseeable that these chord services will gradually rely more on ACE technologies. Consequently, regarding one of the ultimate goals in music informatics as building a human-like music intelligence system, large vocabulary ACE (LVACE) is absolutely a significant part of the machine.

\subsection{ACE as part of artificial musicianship}
Human musicianship requires as least one of the four kinds of trainings: ear training, sight-reading, composition and improvisation, as captured in Figure~\ref{fig:1-musictraining}. MIR researches mostly focus on ``ear training'' and ``sight-reading''. The ability to transcribe ``chords'' obviously belongs to ``ear training''.
\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{1/figures/musictraining.pdf}
\caption{Human music training as related to language training}
\label{fig:1-musictraining}
\end{figure}

Ear training, according to the EarMasterPro \footnote{\url{http://www.earmaster.com/}} (as elaborated in Figure~\ref{fig:1-eartraining}), includes several sub-trainings. The ``identification of chords'' is one of them. Therefore, in building artificial musicianship, ACE plays a key function in the artificial musical ``ear''.
\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{1/figures/eartraining.pdf}
\caption{Human ear training}
\label{fig:1-eartraining}
\end{figure}

\subsection{ACE inspires scientific researches on human audition and mind}
Last but not the least, ACE research, in an algorithmic level, could shed light on the working mechanism of the human auditory system or human perception towards music harmony. This similar motivation is shared by many other artificial intelligent tasks\cite{lecun1995convolutional,hinton1995wake}, where the exploration of algorithmic or machine learning solution itself inspires the scientific researches on working mechanisms of visual perceptions within human brain.

\section{Thesis Structure} \label{sec:1-outline}
This thesis focuses on deep learning based solutions to ACE. The main contributions of this thesis can be found in Chapter~\ref{cp:ghmm}--\ref{cp:jazz}, where Chapter~\ref{cp:ghmm} and ~\ref{cp:endtoend} are parallel sections presenting two different deep learning based LVACE approaches, and Chapter~\ref{cp:jazz} takes one of the approaches and build algorithmic music systems for jazz. Particularly:

\Hsection{Chapter~\ref{cp:intro}} is an introduction to the whole thesis. It defines the problem of ACE, motivates the need for LVACE from different perspectives, and sketches the thesis outline and contributions.

\Hsection{Chapter~\ref{cp:background}} is the literature review. The chapter first lays down the musical fundamentals necessary for a good understanding of ACE. Then it looks back into ACE's history and tries to come up with a storyline which investigates different ACE modules and submodules. Finally it examines various preferences on ACE evaluation, especially some issues and arguments around LVACE evaluation and human annotation subjectivity.

\Hsection{Chapter~\ref{cp:ghmm}} describes a segmentation-classification LVACE approach. It addresses the concrete design of the feature extraction and pattern matching module, where the latter is realized through three deep neural networks. The chapter also explores common variations under such ACE framework, and concludes with insights and pointers to general design guidelines.

\Hsection{Chapter~\ref{cp:endtoend}} demonstrates an end-to-end LVACE approach, where the sequence segmentation and classification are all done by a single recurrent neural network. To accommodate large vocabulary implementation, a skewed class oriented training scheme is used. This scheme is shown to be very effective in improving vocabulary versatility.

\Hsection{Chapter~\ref{cp:jazz}} extends the application of LVACE to jazz music. The chapter first introduces musical fundamentals of jazz. Then it extends the approaches in the previous chapters to implement a jazz ACE system. It further adds on the system an extra ``scale'' estimation process to enable a ``chord-scale'' (see Section~\ref{sec:5-jazzfund} for more details of these musical terms) recognition. Combining with a jazz improvisation musical interface, the chord-scale estimation engine can allow novice users to make good improvisations out of jazz backings.

\Hsection{Chapter~\ref{cp:conclude}} concludes the thesis with pointers to possible future directions of ACE.


\section{Contributions and Publications by the Author} \label{sec:1-contribution}
The major contributions of this thesis are mainly on the deep learning methods for LVACE. Particularly, this thesis proposes two new ACE architectures and applies them to large vocabulary implementation and evaluation:
\begin{enumerate}
\item a segmentation-classification deep learning based ACE system framework;
\item an end-to-end recurrent neural network based ACE approach with even chance training scheme;
\item applies the above two systems to large vocabulary implementation and evaluation.
\end{enumerate}

The thesis also has minor contribution in the application of ACE technologies to jazz:
\begin{enumerate}
\item a jazz chord-scale estimation approach that extends the previously proposed ACE framework with local scale tracking process.
\item two jazz improvisation platforms that enable users to intuitively create melodies based on a chord-scale sequence.
\item an automatic jazz improvisation process that combines the chord-scale estimation system and a note generation process.
\end{enumerate}

In correspond to the thesis contributions, the author has published the following articles:
\begin{itemize}
\item Deng, J., Kwok, Y. K. A Hybrid Gaussian-HMM-Deep-Learning Approach For Automatic Chord Estimation with Very Large Vocabulary, In Proceedings of the 17th International Society for Music Information Retrieval Conference, New York City, USA, 2016
\item Deng, J., Kwok, Y. K. A Chord-scale Approach to Automatic Jazz Improvisation, In Late-breaking/demo Proceedings of the 17th International Society for Music Information Retrieval Conference, New York City, USA, 2016
\item Deng, J., Kwok, Y. K., Automatic Chord Estimation on SeventhsBass Chord Vocabulary Using Deep Neural Network, In Proceedings of the 41st International Conference on Acoustics, Speech, and Signal Processing, Shanghai, China, 2016
\item Hu, X., Deng, J., Zhao, J., Hu, W., Ngai, E. C. H., Wang, R., ... and Kwok, Y. K., SAfeDJ: A Crowd-Cloud Codesign Approach to Situation-Aware Music Delivery for Drivers. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 12(1s), 21.(2015)
\item Deng, J., Lau, F. C. M., and Kwok, Y. K., ArmKeyBoard: A Mobile Keyboard Instrument Based on Chord-Scale System and Tonal Hierarchy. In Proceedings of 40th International Computer Music Conference, Athens, Greece, 2016.
\item Deng, J., Lau, F. C. M., Ng, H. C., Kwok, Y. K., Chen, H. K., and Liu, Y. H., WIJAM: A Mobile Collaborative Improvisation Platform under Master-Players Paradigm. In Proceedings of the 2014 International Conference on New Interfaces for Musical Expression, London, UK., 2014
\end{itemize}

There are currently two articles under review:
\begin{itemize}
\item Deng, J., Kwok, Y. K., Large Vocabulary Automatic Chord Estimation Using Deep Learning: Design Framework and System Variations, submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing, 2016 (under review)
\item Deng, J., Kwok, Y. K., End-to-end Large Vocabulary Automatic Chord Estimation Using Bidirectional Long-Short-Term-Memory Recurrent Neural Network with Even Chance Training, submitted to Journal of New Music Research, 2016 (under review)
%\item Deng, J., Kwok, Y. K., High Level Performance Based on Chord-scale Progression: Towards Building a Music Machine, submitted to Computer Music Journal, 2016 (under review)
\end{itemize}

%So far, this introduction chapter has already briefly summarized the general idea of this thesis. In a word, this thesis is mainly dedicated to large vocabulary automatic chord estimation, so as to approach the ultimate human-like machine chord transcription goal, that tries to recover every subtle flavors of the original recordings.



