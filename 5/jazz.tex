
% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{A Preliminary Approach to Automate Jazz Chord-Scale Estimation and Jazz Improvisation}\label{cp:jazz} % top level followed by section, subsection

Previous chapters have explored ACE in the \textit{SeventhsBass} vocabulary. This vocabulary is mostly covered in music genres such as pop, rock, and folk songs. But chord types such as sevenths extensions, suspensions and alterations are not included in \textit{SeventhsBass}. This chapter, following the original large vocabulary spirit of Fujishima \cite{fujishima1999realtime} and Sheh and Ellis \cite{sheh2003chord}, tries a preliminary ACE solution that handles a much larger vocabulary, and beyond that, puts together a ``chord-scale'' estimation system that could be deployed in an automated jazz improvisation platform.

% ----------------------- contents from here ------------------------
\section{Jazz Fundamentals} \label{sec:5-jazzfund}
This chapter focuses on a chord vocabulary of triads, sixths, sevenths and their extensions, suspensions, and alterations. In particular, it targets at jazz, which is an improvisation based style with complex harmonic structures \cite{hojnackijazz}:
\begin{quote}
One thing that distinguishes mainstream jazz harmony from other tonal styles is the tremendous amount of harmonic color that arises due to the pervasive use of tertian extensions of the basic chord types.
\end{quote}
Different from pop, rock and folk music, which usually have long chord progressions within the same key and only modulate at most a few times during a piece, jazz music often contains a lot of key modulations. A {\it modulation} is \cite{randel1999harvard}:
\begin{quote}
in tonal music, the process of changing from one key to another, or the result of such change.
\end{quote}
Musical key and chord progression are closely related to each other. Many MIR systems \cite{catteau2007probabilistic,noland2009influences,mauch2010simultaneous,papadopoulos2012modeling} have been attempted to extract both at the same time. But these works are all experimented under low modulation rate contexts. While under a jazz context, where modulation rate is much higher, these classical approaches may or may not apply. Hence besides ACE, this chapter will investigate on a different key tracking algorithm in order to also capture the modulations. It should be noted that in {\it modal jazz}, where a piece is constructed horizontally around the melody instead of vertically around the harmonics, the functional role of ``chord progression'' is weaken or eliminated, but there are still harmonic movements, regardless of keys or chords, to support the melody lines.

As jazz is an improvisation based music style, extracting the chord progressions and key modulations could help determine/imply the {\it chord-scale} candidates to improvise over a given harmonic segment. A {\it chord-scale} is \cite{hojnackijazz}:
\begin{quote}
a linear rendering of a complex chord - an extended chord structure, with tensions and non-chord tones arrayed within an octave.
\end{quote}
Each chord-scale is constructed by a root and a scale, where the root is similar to the root of a chord. There are seven commonly used scales in jazz that are derived from the \textit{major} scale. They are called {\it mode}s or {\it modal scale}s. They are:
\begin{enumerate}
\item Ionian: $WWHWWWH$
\item Dorian: $WHWWWHW$
\item Phrygian: $HWWWHWW$
\item Lydian: $WWWHWWH$
\item Mixolydian: $WWHWWHW$
\item Aeolian: $WHWWHWW$
\item Locrian: $HWWHWWW$
\end{enumerate}
where $W$ is a whole step, and $H$ is a half step (note that $W$ = $2*H$). The sequences indicate the arrangement of whole/half step intervals within the scales. These modes, from 1 to 7, can be memorized as left-circular shifting the \textit{major} scale ($WWHWWWH$) one note at a time. Likewise, modes can also be built based on the {\it harmonic minor scale} ($WHWWHW^+H$, where $+$ means an additional half step) or the {\it melodic minor scale} ($WHWWWWH$). Alternatively, there could be other scales out of this construction methodology, such as the {\it whole-half diminished scale} ($WHWHWHWH$), {\it half-whole diminished scale} ($HWHWHWHW$), {\it whole-tone scale} ($WWWWWW$) or {\it chromatic scale} ($HHHHHHHHHHHH$).

Normally, a chord-scale is chosen based on the current musical key context, which is determined by the underlying {\it harmonic functional group} \cite{hojnackijazz,levine2011jazztheory}. Table~\ref{tab:5-chordscale} shows some choices suggested by a jazz guitar tutorial book \cite{jazzguitarbook}. For a specific chord type, there could be multiple choices of scales, but the best picks will be determined by the musical key context, where the scale of choice cannot strongly indicate otherwise.
\begin{table}
\centering
\footnotesize
\begin{tabular}{|c|c|} \hline
Chord & Scale \\ \hline
\textit{7} & Mixolydian, Phrygian-Dominant, Whole-tone \\ \hline
\textit{maj7} & Lydian, Lydian-Dominant, Ionian, Ionian\#5 \\ \hline
\textit{min7} & Dorian, Phrygian, Aeolian \\ \hline
\textit{min7b5} & Locrian, Locrian\#2 \\ \hline
\textit{7b9} & Phrygian-Dominant \\ \hline
\textit{maj7\#11} & Lydian \\ \hline
\textit{maj7\#5} & Ionian\#5 \\ \hline
\textit{dim7} & Whole-half Diminished \\ \hline
\end{tabular}
\caption{Chord-scale choices examples}
\label{tab:5-chordscale}
\end{table}

Chord-scale system is a good way to analyze jazz harmony and melody. But in real improvisation, jazz musicians seldom think of this system. Instead, they memorize all these by heart and improvise using the variations of the passages and patterns they learn through extensive exercises \cite{jazzguitarimpro}. To be precise, instead of generating notes from the scales, they generate phrases that fit the context. Infinite number of note sequences can be created, but those phrases, within all these sequences, are among the most acceptable ones to human musical aesthetics. In addition to creating phrases within a single harmonic region, jazz musicians also pay much attention to the coherence of nearby phrases so as to make the best musical sense possible.

\section{Automatic Jazz Chord Estimation} \label{sec:5-jazzace}
To perform ACE for jazz, the system framework in Chapter~\ref{cp:ghmm} is used. Assuming the segmentation pass can achieve high output quality, the remaining task is to classify chords independently in each segment. Figure~\ref{fig:5-jazzsys} is a succinct version of the system framework, where the segment tiling process is absorbed into the chord classifier module.
\begin{figure}[htb]
    \centering
        \includegraphics[width=0.8\columnwidth]{5/figures/sys.pdf}
    \caption{The Jazz ACE system. It is equivalent to the system framework in Figure~\ref{fig:3-sysover}}
    \label{fig:5-jazzsys}
\end{figure}

Table~\ref{tab:5-aceconfig} shows all ACE configurations considered in the experiment. They are chosen based on the results in Chapter~\ref{cp:ghmm}.
\begin{table}[htb]
\centering
\footnotesize
\begin{tabular}{|c|c|c|} \hline
Dimension & Configuration \\ \hline
deep neural nets & FCNN, DBN, BLSTM-RNN\\ \hline
hidden layers & (800,800)\\ \hline
segment tiling & 6\\ \hline
feature level & notegram(-ns), chromagram (-ch) \\ \hline
\end{tabular}
\caption{ACE configurations}
\label{tab:5-aceconfig}
\end{table}

\subsection{Experimental Setup}
In this study, 99 pieces of jazz chord comping + soloing extracted from a jazz guitar book \cite{jazzguitarbook} (JazzGuitar99) are used as the training dataset, and 7 pieces of jazz comping from Gary Burton's on-line course \cite{garyburtoncourse} (GaryBurton7) are used as the test dataset. JazzGuitar99's annotations are taken directly from the book, and GaryBurton7's annotations are taken from the leadsheets provided along with the course. All training data are augmented 12 times using the same procedure as in Chapter~\ref{cp:ghmm} and ~\ref{cp:endtoend}. The vocabulary has 36 types \footnote{They are: $maj$, $min$, $min6$, $6$, $maj7$, $maj7\#5$, $maj7\#11$, $maj7b5$, $min7$, $minmaj7$, $min7b5$, $min7\#5$, $7$, $7b5$, $7b9$, $7\#9$, $7\#5\#9$, $7\#5b9$, $7b5b9$, $7\#5$, $7sus4$, $aug7$, $dim7$, $ maj9$, $min9$, $9$, $9\#11$, $min11$, $min11b5$, $11$, $min13$, $maj13$, $13$, $13b9$, $69$ and $N.C.$}. Note that inversions are not considered in this preliminary jazz ACE study because: 1. there are very few inversion notations in the currently used datasets; 2. it will result in a huge number of classes.

%In the second study, the training/validation dataset is extracted from the CDs of a jazz guitar improvisation tutorial \cite{jazzguitarimpro} (JazzImpro96) and a practical jazz guide \cite{pracjazz} (PracJazz76). Totally they contain 172 tracks. All annotations are taken from the leadsheets in the books. The datasets of the previous study is used for testing. The vocabulary has 60 types\footnote{$maj7$, $min7$, $7$, $maj7\#11$, $min9$, $9sus4$, $7sus4$, $maj$, $7b9$, $9$, $13$, $9\#11$, $7\#9$, $min7b5$, $min$, $minmaj7$, $min6$, $7b13$, $7(9, \#11, 13)$, $7\#5$, $6$, $maj9$, $7(b9, \#9, b13)$, $7(b9, b13)$, $7(\#9, b13)$, $7(\#9, b9)$, $7\#11$, $9(b9, b13)$, $69$, $13b9$, $9b13$, $7(9, \#11)$, $7(13)$, $9(13)$, $7(alt)$, $dim7$, $min7(11)$, $7(b9, 13)$, $7(\#11, 13)$, $min7b9$, $7(9, 13)$, $7(9)$, $min7b5(11)$, $7\#5(\#9)$, $min7(11, 13)$, $9(6)$, $aug7$, $7b5$, $maj13$, $min11$, $7\#5\#9$, $11$, $min13$, $7\#5b9$, $maj7\#5$, $min11b5$, $maj7b5$, $min7\#5$, $7b5b9$ and $N$}.

%All training data are to be used at either notegram (-ns) or chromagram (-ch) level. Assuming 12-tone equal temperament, they can be augmented by pitch shifting with zero padding (for -ns), or circular pitch shifting (for -ch) to all 12 keys. Adjusting the chord labels accordingly, this results in 12 times of training data.



\subsection{Results and Discussions}
Following the MIREX ACE convention, system performances are reported using \textit{WCSR}. The \textit{WCSR} computing procedure in its fairest/strictest sense should regard each chord as it is without applying any sort of mapping scheme. In the following, each system is evaluated in this way. The baseline is an augmented Chordino with jazz vocabulary extension (Jazz-Chordino). The augmentation is done within its GMM-HMM process by applying the jazz chord dictionary to the Gaussian emission model, whose setting is given in Table \ref{tab:5-jcgau}.
\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{|c|c|c|} \hline
      & $\mu$ & $\sigma^2$ \\ \hline
Bass - Chord Bass & 1 & 0.1 \\ \hline
Treble - Chord Note & 1 & 0.2  \\ \hline
Neither bass nor treble & 0 & 0.2 \\ \hline
N.C. (for all notes)  & 1 & 0.2  \\ \hline
\end{tabular}
\caption{Gaussian model of Jazz-Chordino}
\label{tab:5-jcgau}
\end{table}

All systems are tested using the GaryBurton7 dataset \footnote{Composition of chords in GaryBurton7: \textit{maj}:0.09; \textit{min7}:0.13; \textit{7}:0.22; \textit{min7b5}:0.12; \textit{7b9}:0.06; \textit{min}:0.1; \textit{maj}:0.14; \textit{others}:0.14.}. Results are shown in Table \ref{tab:5-jazz-wcsr}. Jazz-BLSTM system performs the best, and outperforms Jazz-Chordino by about 10 points. The ranking is very similar to the \textit{SeventhsBass}', but these results are in a sense more convincing, since the test set is not dominated by \textit{major} and \textit{minor} chords. In fact, the chord composition in GaryBurton7 is relatively balanced, although rare chords are still rare. These results demonstrate the advantage of the proposed system framework for very large chord vocabulary.

Meanwhile, notice that the \textit{SQ} (segmentation quality) of these systems are all relatively high, and these are achieved in pure jazz test audio. All systems share Jazz-Chordino's GMM-HMM segmentation process. The differences among the \textit{SQ} scores are caused by different merging of consecutive chords in different systems. (In this sense, the Jazz-DBN-ch system is probably constantly generating the same chord).
%Obviously, the success of Jazz-BLSTM owes to the success of the GMM-HMM segmentation at first.
%then based on the segmentation it performs classifications without taking care of chord progression context.
%This task is comfortable to deal with by a fixed-length input deep learning model. The advantage may not be obvious under a small chord vocabulary, but is obvious under a large chord vocabulary.

\begin{table}[t]
\centering
\footnotesize
\begin{tabular}{|c|c|c|} \hline
systems & \textit{WCSR} & \textit{SQ}\\ \hline
Jazz-Chordino & 57.99 & 81.68\\ \hline
Jazz-FCNN-ns & 61.81& 76.18\\ \hline
Jazz-DBN-ns & 62.33& 80.73\\ \hline
\textbf{Jazz-BLSTM-ns} & \textbf{66.41} & 80.78\\ \hline
\textbf{Jazz-FCNN-ch} & \textbf{65.65} & 81.94\\ \hline
Jazz-DBN-ch & 4.56& 20.42\\ \hline
Jazz-BLSTM-ch & 63.72 & 82.22\\ \hline
\end{tabular}
\caption{Jazz ACE performances. The Jazz-DBN-ch result, due to excessive regularization, could be considered as an outlier.}
\label{tab:5-jazz-wcsr}
\end{table}

\subsection{Extension - Jazz Scale Estimation}
The above jazz ACE system can be extended to jazz scale estimation, thereby achieving a unified chord-scale estimation system. As reviewed in Section~\ref{sec:5-jazzfund}, the scales are chosen based on the harmonic functional group, which establishes a temporary tonal center, or a key. Consequently, a natural way to perform jazz scale estimation is by local key estimation.
\begin{figure}[htb]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/localscale.pdf}
    \caption{Template-based local scale tracking. A scale is estimated within a context window of chords. ``S'' stands for segment; ``C'' stands for chord.}
    \label{fig:5-localscale}
\end{figure}
Figure~\ref{fig:5-localscale} shows the extended ACE system for local scale estimation, where ``chordo'' means the probabilities of each chord conditioned on the chroma input. Different from the chord-key estimation systems proposed by Mauch \cite{mauch2010simultaneous} and Catteau \cite{catteau2007probabilistic}, the scale is not estimated by a generative model, but a discriminative template-based model similar to Rocher et al.'s approach \cite{rocher2010concurrent}. Instead of using a well-known key profile \cite{temperley2004cognition}, binary ``scale templates'' ($ST$) are used to compute a local scale posterior probability surface from the ``chord templates'' ($CT$), similar to the key estimation method in \cite{hu2015safedj}. Since each local scale cannot be determined by just one chord, a context window is introduced to collect a neighborhood of 3 chords. As a result, a scale's fitness of the context is computed as:
\begin{equation}
\text{fitness} = \sum_{i=1}^{12} \sum_{j=1}^3 {ST_i\cdot CT_{ij}},
\end{equation}

For a given context, the system will decide a list of scale candidates, and then pick the one with the best fitness:
\begin{equation}
scale = \max_k (\text{fitness}_k).
\end{equation}
The template-based local scale estimation is implemented during the ISMIR 2016 Hackathon \footnote{http://labrosa.ee.columbia.edu/hamr\_ismir2016/}. Figure~\ref{fig:5-chordscale} shows an example output of this chord-scale estimation process with ``Olhos de Gato'', where the labels in red indicate the estimated chord-scales.
\begin{figure}[h]
    \centering
        \includegraphics[trim={0 4cm 0 2cm},clip,width=0.8\columnwidth]{5/figures/chordscale-demo.pdf}
    \caption{Chord-scale tracking demo output from a leadsheet}
    \label{fig:5-chordscale}
\end{figure}

However, since this is a relatively new direction in MIR, there is not any well-established labeled dataset available for evaluation. Therefore this system has not been formally evaluated under any objective measure yet.

The jazz chord-scale estimation research has its straightforward application to new interfaces for musical expressions. In the rest of this chapter, two mobile jazz improvisation platforms will be introduced in Section~\ref{sec:5-wijam} and ~\ref{sec:5-akb}. Finally, Section~\ref{sec:5-puttogether} will seek to put the chord-scale estimation system in a fully automatic jazz improvisation context.

\section{Jazz Improvisation Platform - WIJAM} \label{sec:5-wijam}
WIJAM is an impromptu iOS mobile application for a group of musical novices to jam along with a music master. The master provides backings, directs the musical flow and gives feedbacks to the players. The players improvise along with the master's guidance.

WIJAM, according to Weinberg\cite{weinberg2005interconnected}, is a ``small-scale local system", which can be characterized as ``collaborative musical network ... that support three to ten players in close proximity, which allows for detailed and subtle interpersonal interactions". Under the ``theoretical framework of musical interconnectivity''\cite{weinberg2005interconnected}, WIJAM can be considered structure-centered and process-centered, where ``structure'' is manifested in the absolute musical arrangement control of WIJAM master, and ``process'' is done when WIJAM players express intuitively their musical feelings within the bounds as defined by the WIJAM master.

In terms of organization and architecture, WIJAM is a ``synchronous centralized network'' with a ``flower topology'', where music is being generated in real-time with a central hub, and the degrees of freedom in terms of the nodes' expression are limited to a level such that the musical outcomes are at least musically harmonious.

\subsection{Design Concepts}
WIJAM's design follows Blaine's guidance \cite{Blaine2003}:
\begin{quote}
The underlying premise of most collaborative interface design is that with various design constraints, playing music can be made accessible to non-musicians ... at the expense of limiting the musical range and possible gestures associated with sound in a collective space.
\end{quote}
But as pointed out in the same paper, such a guideline has its drawback:
\begin{quote}
... many of the simple-to-use computer interfaces proposed for musical control seem, after even a brief period of use, to have a toy-like
character and do not invite continued musical evolution.
\end{quote}
Although it goes on to argue that this is only true for expert musicians, but ``balancing this trade-off is a key concern for designers", as pointed out in \cite{blaine2003collaborative}. This point is echoed in many other papers\cite{xambo2011multi}, emphasizing that ``provide novices with essential goals and experts with additional goals". Trying to meet this balance, WIJAM equips the players with an easy to learn and easy to play keyboard, while at the same time providing ``a knowledgeable person to stand by and assist the players" \cite{Blaine2003}--the master. The players performance bound is imposed upon by the master, which should give a large enough space for the players to show off their virtuosity.

\subsection{System Overview}
Figure~\ref{fig:5-BigPicture} shows the big picture of WIJAM. There are two types of active entities: the master, who initiates and orchestrates the jamming, and the players who participate in the jamming. There is a passive entity: a loudspeaker system, which is connected to the master.

\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/BigPicture.png}
    \caption{The big picture of WIJAM. The music collaboration is achieved under the ``master-players" paradigm.}
    \label{fig:5-BigPicture}
\end{figure}

Figure~\ref{fig:5-FlowChart} is the flowchart of the WIJAM session process. At the beginning, the master hosts a \textit{MIDINetworkSession} as a jam session service to be discovered and connected to. Then the players join the session. After that the master sends an ``assignment" package to each player. The package contains an instrument ID, and a chord-scale. The master signals the start of the jam by switching on the backing music. When the players start to jam, they send MIDI performance contents to the master via \textit{coreMIDI}. The master monitors all the performance, renders the notes in the chosen instrument sounds and mixes them with the backing into one output stream. While jamming, the master orchestrates everything to fit to the backing music by instantly changing the assignment or providing performance cue feedbacks to the players such as ``good", ``solo", ``fast", ``calm", etc. When they finished jamming a song, the master gives an overall score as well as an individual score to the players.
\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/Flowchart.png}
    \caption{The flowchart of WIJAM.}
    \label{fig:5-FlowChart}
\end{figure}

\subsection{Master Machine}

\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/MasterVC.jpg}
    \caption{WIJAM's Master Interface}
    \label{fig:5-MasterVC}
\end{figure}

The internal structure and layering of the master machine \footnote{https://github.com/tangkk/MasterMachine.git} is shown in the middle part
of Figure~\ref{fig:5-Layering}. The core modules are detailed below:
\begin{figure*}[htbp]
    \centering
        \includegraphics[width=0.8\textwidth]{5/figures/Layering.png}
    \caption{The internal layering and structure of WIJAM. The data flows from the master machine (middle) to the player machine (right) through the bidirectional communication channel, and vice versa.}
    \label{fig:5-Layering}
\end{figure*}

\Hsection{Master Interface}
The master interface is shown in Figure~\ref{fig:5-MasterVC}. In the top left corner there is a backing selector which allows the ``master" to initiate the backing music. Moving downwards there is a chord-scale panels. They are particularly important for orchestrating the musical flow. At the bottom there are six consoles, from A to F, each for an individual player. They provide performance feedback to the players as well as music output level balancing.

\Hsection{Arranger}
This allows the master to manipulate chords, scales, instruments, and feedbacks. These messages are sent via \textit{MIDI sysEx} messages.

\Hsection{Virtual Instruments}
It stores a library of digital musical instruments in the form of samplers. The audio samples are managed using \textit{AUPreset} and \textit{AUSampler} technologies\cite{AUSampler}. The \textit{AUPreset} files are used to map audio samples directly to MIDI numbers and velocity ranges.

\Hsection{Jam Session Host}
It hosts a service which can be discovered and connected to by the player machines. \textit{MIDINetworkSession} is used to enable a \textit{Bonjour} service. It is to be discovered by the player machines' Bonjour service browsers, and to be connected to by the player machines' \textit{MIDINetworkSessions}.

\subsection{Player Machine}
The player machine's layering is described on the right hand side of Figure~\ref{fig:5-Layering} and its interface on Figure~\ref{fig:5-PlayerMachineVC} with the jam console on the left and the keyboard on the right. \footnote{https://github.com/tangkk/PlayerMachine.git} The jam console is designed to discover and connect to the master machine, and the keyboard is for musical expression. The following items summarize the working mechanism of the keyboard:
\begin{figure}[htbp]
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1.2in]{5/figures/PlayerMachineVC.png} &
\includegraphics[width=1.2in]{5/figures/Simple.png} \\
\end{array}$
\end{center}
\caption{WIJAM's Player Interface}
\label{fig:5-PlayerMachineVC}
\end{figure}
\begin{itemize}
\item
The y position determines the pitch, where higher position yields higher pitch.
\item
At any time the keyboard is filled with the chord-scale assigned by the master machine.
\item
The x position determines the note velocity. A larger x position value gives higher velocity.
\item
When sketching, a note is generated when the it starts or when the curve comes to a stationary point.
\end{itemize}
This keyboard is easy to use for novice players, by abstracting away most complicated musical context. It allows the players to do a high-level melody improvisation.

\subsection{Demos}
There are two basic demos \footnote{\url{http://www.youtube.com/watch?v=Y0PnKBrgzgw}} and one advanced demo \footnote{\url{http://www.youtube.com/watch?v=16dWj5G9UKw}} for WIJAM. The basic demo shows how WIJAM works, and provides tips for using the master machine and the player machine. The audio track is an unmodified recording of the original playback. Before the jam starts, the players are told to follow their ``musical feelings" based on the backing. As can be heard in the video, the music outcome is quite pleasing, even at the critical ``key modulation" points: 2:30 and 2:43. Note that as the jam goes on, because the players have little idea about what the exact notes they are playing, the ``avoid note", the most dissonant note within the chord-scale, may be played on downbeat. This may happen, but with a very small chance.

The ``trombone" player and the two ``guitar" players are with zero training in musical instruments. The ``piano" player has some limited
experience with piano before. Even so, the piano player is able to inject a very beautiful solo during the jam. The ``piano" player apparently plays the best music in this jam session. This somewhat justifies the ``balance" problem in the ``Introduction" section of this Section, in that WIJAM actually allows advanced players to show off their virtuosity while also enabling an acceptable level of performance for the novice players.

The advanced demo is a bonus track featuring the designer of WIJAM playing and overdubbing a whole jam session. It shows some advanced features of the PlayerMachine. The audio track is an overdubbing of each instrument track plus the backing track.

\section{Jazz Improvisation Platform - ArmKeyBoard} \label{sec:5-akb}
The piano keyboard, although is versatile and popular, has a lot of drawbacks. The same type of chord or scale in different keys are laid out differently, which adds to the learning difficulty. Additionally, the keyboard has a linear layout of the black and white keys, which works well with music expressions that exhibit certain linearity , but is less effective for modernistic non-linear styles such as that of serialistic and stochastic music \cite{Mitsuko:Schoenberg}.

Trying to solve the above problems, a new type of keyboard is designed. Based on the NIME design principles \cite{cook2001principles}--specifically the ``Make a piece, not an instrument or controller" and ``Instant music, subtlety later"--the keyboard leverages a chord-octave-scale sequence grid to pack 88 keys into a 15--17 keys-sized screen, and features an almost zero learning curve for the production of beautiful and sophisticated melodies. It offers both linear and non-linear layouts. The non-linear layout is mapped to a user chosen image by an algorithm based on contour separation and tonal hierarchy. This is called ``ArmKeyBoard", where ``ArmKey" means suitable, comfortable, and in-tune, in the author's spoken dialect.

\subsection{Two Types of Keyboard Layout}
In the remaining discussion, ``keyboard" refers to an instrument implementing a series of key-note pairs and deterministically
generates a note when a key is pressed. ``Layout" refers to the spatial arrangement of those key-note pairs.

Linear layout is characteristic of a piano. From left to right, each key is mapped to a unique note value. Every next key is mapped to
a note value exactly 1 (in MIDI terms) higher than the previous one. This has a significant impact on music making, since people naturally feel more comfortable with playing on adjacent keys than non-adjacent keys, leading to smaller intervals appearing more often than larger ones, as can be seen in music literature such as \textit{the Real Book} \cite{therealbook6th}.

Non-linear layout can have many more possibilities, such as a random note being paired with a random key or one note being paired with
several keys. Note that in the current discussion, several notes being paired with one key is not valid by the definition of keyboard. Non-linearity may further allow using any key setting other than the traditional setting. For example an image can be divided into several sections, each serving as a key of the keyboard. The idea of non-linear keyboard is not new. There are existing applications such as \cite{kontakts} or papers such as \cite{kruge2011madpad} talking about similar ideas, most of which are built around the idea of sampling. In Armkeyboard, however, the audio content generated by a key is a note.

\subsection{Chord, Scale and Octave}
ArmKeyBoard treats the small screen as a cache, caching the currently playing chord-scale in the current octave range, while other
octaves and chord-scales are waiting to be loaded when needed. In the current design, 15--17 notes---two octaves of a scale, are cached

Changing chord-scale or octave on a piano in real time is easy for a pianist, but could be a nightmare for non-pianists. Therefore, ArmKeyBoard needs a special mechanism to load other chord-scales and octaves into the foreground, so that the player can easily switch music expression ranges in real time. To this end, a chord-octave-scale sequence grid as shown in Figure~\ref{fig:5-cosgrid} is designed.
\begin{figure}[htbp]
\begin{center}$
\begin{array}{cc}
    \includegraphics[width=1.2in]{5/figures/ChordOctaveScaleGrid.PNG} &
    \includegraphics[width=1.2in]{5/figures/ChordScalePreset.PNG}\\
\end{array}$
\end{center}
\caption{On the left is the chord-octave-scale grid, where each square can be set as one chord-octave-scale
combination (such as C-4-Lydian), and consecutive squares form a sequence which can be saved as preset; The sequence is read from left to right, and when it reaches the rightmost, back to the leftmost square on the next line; On the right is the chord-octave-scale preset browser looking at the already saved chord-octave-scale sequence presets.}
\label{fig:5-cosgrid}
\end{figure}

\begin{figure}[htbp]
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1.2in]{5/figures/Gravity0.jpg} &
\includegraphics[width=1.2in]{5/figures/GravityX.jpg} \\
\end{array}$
\end{center}
\caption{Gravity X gesture, which is used for switching to the next or previous page of notes determined by the chord-octave-scale combination at the next or previous square within the sequence.}
\label{fig:5-GravityXGesture}
\end{figure}

Users can switch between different chord-octave-scales using a gravity X gesture (Figure~\ref{fig:5-GravityXGesture}). Meanwhile, users can also flip octaves within the same chord-scale using swipe gestures. To summarize, in Figure~\ref{figChordOctaveScaleControl}, the screen is a cache of the active note space, while the spaces around the active space can be loaded in real-time via gravity X or swipe gestures.

\begin{figure}[htbp]
\centering
\includegraphics[width = 3.2in]{5/figures/ChordOctaveScaleControl.png}
\caption{Chord-octave-scale control. The horizontal arrows indicate changing page of notes according to chord-octave-scale sequence, while the vertical arrows indicate changing page of notes to a higher or lower octave only.}
\label{figChordOctaveScaleControl}
\end{figure}

\subsection{Expression Parameters}
Because the proposed design is based on the piano keyboard, the most dominant expression parameter, velocity, should be implemented. In the
linear layout, since key-note mapping is 1-to-1 and the position of each key is equally distributed along the y-axis, velocity can be easily controlled by position X. While in the non-linear layout, position X cannot be used because keys can be in any shape and anywhere; thus Gravity Y is used to control the velocity (Figure~\ref{fig:5-GravityYZGesture}). Note that sustain is not considered in the current design, since if a hand gesture were to convey what is originally conveyed by foot, it might make learning difficult for the ordinary users. A gravity Z gesture is to restart the keyboard again (Figure~\ref{fig:5-GravityYZGesture}).
\begin{figure}[htbp]
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1.2in]{5/figures/GravityY.jpg} &
\includegraphics[width=1.2in]{5/figures/GravityZ.jpg} \\
\end{array}$
\end{center}
\caption{Gravity Y gesture (on the left), which is used for controlling note velocity, leading to a smaller velocity with a larger angle to the horizontal plane; Gravity Z gesture (on the right), which is used for quitting the current keyboard to reset everything again}
\label{fig:5-GravityYZGesture}
\end{figure}

\subsection{Linear Layout and Mapping}
ArmKeyBoard has both linear and non-linear keyboard layout, called ``AKB1" and ``AKB2" respectively. The discussion is based on the iOS platform.

``AKB1" (Figure~\ref{fig:5-AKB12}) contains 15--17 notes within the active chord-octave-scale and they are mapped linearly to 15--17
bars equally divided along the y-axis. The velocity is controlled by the X position.

\subsection{Non-linear Layout and Mapping}
``AKB2" is a user selected image (Figure~\ref{fig:5-AKB12}). The image is algorithmically divided into contours and they are algorithmically mapped to the 15--17 notes within the currently active chord-octave-scale. The algorithms are described below.
\begin{figure}[htbp]
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1.2in]{5/figures/AKB1.PNG} &
\includegraphics[width=1.2in]{5/figures/AKB2.PNG} \\
\end{array}$
\end{center}
\caption{AKB1 (on the left) is a linear keyboard with a higher pitch at smaller y position value, and larger note velocity at larger x position value, each page contains 15--17 notes; AKB2 (on the right) is a non-linear keyboard mapping the page of 15--17 notes to the detected contours within the user selected image, where the mapping procedure is based on the correlation between the importance of contours (or regions) and the tonal hierarchy of notes.}
\label{fig:5-AKB12}
\end{figure}

\Hsection{Contour Separation}
The contour separation is processed using opencv \cite{opencv}. The image is first transformed to opencv \textit{Mat} which is then passed to a contour separation function. The function then: Step 1, turns the \textit{Mat} into gray scale and slightly performs a blur operation on it; Step 2, passes the output of step 1 (a gray scale \textit{Mat}) to an edge detection function (the output is a binary \textit{Mat} with the edge pixels set as step 1); Step 3, passes the output of step 2 to a \textit{findContour} function, which finds contours, stores them in an array and calculates the contour hierarchy (a tree structure describing the inclusion relationship of contours); Step 4, calculates the area of each contour, discards those below a certain size and deletes their nodes in the hierarchy; Step 5, creates an outer contour which is the whole screen subtracted by all the contours output by step 4. The output of all the above steps is an array of valid contours (each contour is itself an array of its vertices), and a hierarchy structure describing the inclusion relationship of these contours.

\Hsection{Contour Ranking}
Next step is to decide which note to map to which contour. The minimal musical concern is, when the keyboard is being played, the notes being generated should at least imply the currently active chord-scale most of the time. Note that it is not necessary that it should ``always" behave this way, but ``most of the time". For example, in \textit{G-Ionian}, the keyboard is supposed to generate notes that form a tonal gravity at G and imply G major chord most of the time, but sometimes it may also sound like \textit{C-Lydian} (tonic at C).

More assumptions are needed to connect this musical concern to contours. Assume that most user tends to tap on: 1, a contour with a larger area; 2, a contour closer to the center of the screen; 3, a contour that contains more sub-contours. Based on how often most users will tap on a contour, its importance can be determined. Thus in the implementation, contours are ranked based on the weighted sum of
the above three indices. This corresponds to how important a note is in implying a certain chord-scale, which will be discussed below.

\Hsection{Tonal Hierarchy}
Similar to ranking contours, if the notes within a chord-scale is also ranked, then what is left is to map the two rankings. According to \cite{jarvinen1995tonal}, there is a certain tonal hierarchy within a chord-scale being played in bebop style jazz music, and this finding actually corresponds to the avoid note issue \cite{nettles1987harmony}. The tonal hierarchy theory says during the performance of a certain chord-scale, some notes are more often heard than others.

If the notes are to be divided into a hierarchy according to how often they appear, the first class contains chord tones (or chord notes), the second class contains those a whole step above the chord notes and finally those half step above, with exceptions. The avoid note issue expresses basically the same idea, but with ``more often heard" replaced by ``more often played".

Table~\ref{tab:5-tonalhierarchy} is a result of the tonal hierarchy theory, which lists all the hierarchies \cite{nettles1987harmony} of some of the most frequently used chord-scales \cite{burtonJazzImpro}. The scale degree notation is
used instead of note names. Note that symmetrical diminished scale and it has no hierarchies in this taxonomy. To deal with hierarchy across octaves, a heuristic rule is that the same pitch-class belongs to the same hierarchy level and a lower octave pitch has a higher priority than a higher octave pitch.

\begin{table}
\centering
\caption{Tonal Hierarchies in ArmKeyBoard. L1 is the first level of notes which are to be mapped to regions with highest importance, and L2 to be mapped to regions with second highest scores, then L3 to be mapped to the least important regions.}
\begin{tabular}{|c|c|c|c|} \hline
Scale & L1 & L2 & L3\\ \hline
Lydian & 1, 5, 3, 7& 2, \#4, 6 & \\ \hline
Ionian & 1, 5, 3, 7& 2, 6 & 4\\ \hline
Mixolydian & 1, 5, 3, b7 & 2, 6 & 4\\ \hline
Dorian & 1, 5, b3, b7& 2, 4 & 6\\ \hline
Aeolian & 1, 5, b3, b7& 2, 4 & b6\\ \hline
Phrygian & 1, 5, b3, b7& 4 & b2, b6\\ \hline
Locrian & 1, b5, b3, b7& 4, b6 & b2\\ \hline
Lydian b7 & 1, 5, 3, b7& 2, \#4, 6 &\\ \hline
Altered & 1, 3, b7& \#4, b6, b2, \#2 & 5\\ \hline
Whole-half Diminished & none & none &\\ \hline
Melodic Minor & 1, 5, b3, 7& 2, 4, 6 &\\ \hline
\end{tabular}
\label{tab:5-tonalhierarchy}
\end{table}

\Hsection{The Final Mapping}
The final mapping is not so obvious as it may seem. Although there are already a ranking of contours and a ranking of 15--17 notes within a chord-scale, they are by no means simply 1-to-1 mappings, because in reality it is not clear how many contours there are and how large each of them is until the user selects an image. In view of this complication, a heuristic based algorithm is devised to do this final mapping:
\begin{algorithm}
\caption{Contour-Note mapping}
\begin{algorithmic}
\STATE
1. Divide the screen size by the number of notes, and name the result $RPN$.
\STATE
2. Look at the $ ratio = Area(contour) / RPN $ of the top item of the sorted contour list (regarded as a stack). \newline If $ratio>=1$, do step	3; otherwise do step 4. Repeat until no contour left in the stack.
\STATE
3. Map notes to contour: pop the contour, pop the top $ ceil(ratio)$ notes and pair them up. Go back to step 2.
\STATE
4. Map contours to note: pop the contour, pair it up with the first	note. Add $ratio$ to $accum$. If $accum>=1$, clear $accum$ and pop the note. Go back to step 2.
\end{algorithmic}
\end{algorithm}
With this, the most important notes are mapped to the most important contours, and contour with larger areas will contain more notes. But since multiple notes cannot be mapped to a single key, they need to be decoupled  within a contour that has more than one note. Instead of further separating a shape-unpredictable contour into several sub-contours, it should be noted that the real ``key" in question is composed of pixels, and thus a heuristic method is used to decouple the notes is to distribute their keys across the contour according to a formula related to pixels and their RGB value:
\begin{equation}
\mathit{noteIdx = ((X + Y) \% 10 + (R + G + B)) \% (15\ or\ 17)}
\end{equation}
Where 15 or 17 is the number of notes. This whole scheme tries to make position affect less
and RGB affect more, while making sure all the notes are included regardless of the image.

\subsection{Demos}
There is a demo of Armkeyboard \footnote{\url{https://www.youtube.com/watch?v=ZhTleEXKeu4}}. The first part shows Armkeyboard's performance on a jazz backing track, and the second part shows a few solo performances. Besides the demo, the author has also applied Armkeyboard in Gary Burton's on-line jazz improvisation course to complete the peer reviewed assignments. In all 6 assignments, it gets an average of 3 points out of the maximum 5 points.


\section{Putting It Together}\label{sec:5-puttogether}
The modules in Section~\ref{sec:5-jazzace} to ~\ref{sec:5-akb} can be put together and form a semi-automatic or fully automatic jazz improvisation machine. The differences among these approaches are the way they deal with generation of note sequence within a chord-scale context.

\subsection{Chord-scale informed user improvisation}
The simplest form would be to only provide the platform with timed chord-scale sequence information, and let players input note sequence. First the jazz backing track is analyzed into segmented chord-scale sequence, then it is programmed into the improvisation platform. These information can automatically guide users with little musical knowledge to improvise jazz with at least the proper choice of chord-scale.

\subsection{Markov model note sequence generation}
A more intelligent approach is to generate note sequence within a chord-scale context using a Markov model. This model has two sets of parameters: the note prior probability matrix and the note transition matrix. These matrices can be trained from existing jazz solo MIDI datasets such as the Weimar Jazz Dataset \footnote{http://jazzomat.hfm-weimar.de/dbformat/dboverview.html}\cite{abesser2013introducing}.

There is a preliminary implementation of this Markov model based note generator together with the template-based scale tracker during the ``Science of Music Hackathon'' in August 2016 \footnote{http://labrosa.ee.columbia.edu/hamr\_ismir2016/}. In this implementation (Figure~\ref{fig:5-hmm1}), a simplified version of the model is built to generate sequence of ``pitches'' instead of ``notes'', where the former do not have duration information but the latter do. The note sequence generation of the Markov chain is constraint by the chord-scale context, namely, only pitches indicated in the chord-scale are allowed.

\begin{figure}[htb]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/hmm1.pdf}
    \caption{The Markov model for pitch sequence generation}
    \label{fig:5-hmm1}
\end{figure}

The code base of this project is available on-line \footnote{https://github.com/tangkk/chordscale}. It depends on the \textit{pretty-midi} \cite{raffel2014intuitive} library to do MIDI interfacing and perform simple sound synthesis. Several preliminary demos can also be found in the code base, showcasing simple chord-melody outputs from the system.

\subsection{RNN-DBN automatic note sequence generation}
To the other extreme, it could be a fully artistically automatic improvisation process if the ``patterns of choices'' from real jazz practice \cite{jazzguitarimpro,pracjazz} are modeled and learned. These are sequences of notes (each of them with both pitch and duration) within the context of chords or chord progressions. They can be well captured by sequential models such as an RNN using the chordal context as the starting cue, with the discriminative objective being whether the sequence of notes are artistically ``acceptable'' or not. This is the discriminative part of the model, and it is similar to the LSTM semantic analysis model by Maas et al.\cite{maas2011learning}.

Note that this discriminative model cannot capture generative details. Hence there should be a generative model inserted, and thus it becomes a discriminative-generative model. Referring Boulanger's RNN-RBM based symbolic music generation system \cite{boulanger2012modeling}, if an instance of DBN (instead of RBM) is inserted between the output layer and the LSTM layer of the previous discriminative model, the resulting network will be able to both classify a sequence to labels and generate a sequence based on the prior labels (Figure~\ref{fig:5-rnndbn}).

\begin{figure}[htb]
    \centering
        \includegraphics[width=0.6\columnwidth]{5/figures/rnndbn.pdf}
    \caption{The RNN-DBN for note sequence generation}
    \label{fig:5-rnndbn}
\end{figure}

In this case, there needs to be a set of training cases for every chord-scale. By training the model with jazz lick patterns, a sequence of ``acceptable'' notes could hopefully be automatically generated by the chord-scale changes estimated from the backing track.


% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------



 






