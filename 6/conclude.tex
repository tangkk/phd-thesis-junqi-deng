
% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Conclusion}\label{cp:conclude} % top level followed by section, subsection

% conclusion outline:
% summary of major contributions (the major takeaways)
%	- large vocabulary with inversions
%	- the gmm-hmm-dl system: lstm based handle long-tail chords nicely, others overfit chords
%	- the end-to-end blstm-rnn system: segmentation quality not good enough, even-chance training work
%	- the auto jazz improvisation: jazz chord segmentation good, chord-scale system still in preliminary stage, but very possible to improve in the future
%
% future directions
%	- combine with Filip's work (feature learning, new chroma)
%	- hierarchical blstm-rnn to better segmentation quality
%	- data collection, ground-truth subjectivity issue, subjective test as the most objective goal
%	- jazz functional ground tracking (evaluation part)
%	- RNN-DBN based jazz lick generation


% ----------------------- paths to graphics ------------------------

% change according to folder and file names
\ifpdf
    \graphicspath{{8/figures/PNG/}{8/figures/PDF/}{8/figures/}}
\else
    \graphicspath{{8/figures/EPS/}{8/figures/}}
\fi

% ----------------------- contents from here ------------------------

This chapter concludes the thesis with some final remarks and points to possible future directions in ACE related MIR researches. Section~\ref{sec:6-recap} will first review all these contributions briefly, and Section~\ref{sec:6-future} will suggest some possible future works that might follow up the current state of works.
%Chapter~\ref{cp:ghmm} to ~\ref{cp:endtoend} each has its own contributions in terms of new approaches to LVACE. Chapter~\ref{cp:jazz} has contribution on the application of ACE technology to jazz domain and its extension to other jazz related issues.

\section{Major Findings Recap} \label{sec:6-recap}
The major research target of this thesis is large vocabulary automatic chord estimation, or LVACE. The motivation of this research originates from the way musicians approach towards chord annotation, which is well described in Chapter~\ref{cp:intro}, that:
\begin{quote}
...those chords are often captured in great details, with large vocabulary including the suspensions, extensions, inversions and even the alternations, that try to recover every subtle flavor of the original recordings by means of these handy chord representations.
\end{quote}
Therefore it is necessary for an ACE system to also incorporate such large vocabulary as a presumption to pass the \textit{Turing test}, which is the ultimate goal of any kind of artificial intelligence.

However, most of the ACE approaches to date do not consider large vocabulary. Instead, they normally take a shortcut \textit{majmin} vocabulary due to various reasons, including the lack of training data for long-tail chords, and the pursuing for higher evaluation scores. In view of this, the thesis tries to devise some novel ways to deal with large vocabulary issues in ACE in order to make up for this gap.

\Hsection{Chapter~\ref{cp:ghmm}} proposes a hybrid GMM-HMM and deep neural nets system framework to solve the LVACE problem. According to the ACE system taxonomy in this thesis, this approach belongs to the ``local feature extraction - global segmentation - local classification'' class. Particularly, it assigns the segmentation and classification into two different processes. The rationale behind this separation is an observation that most MIREX ACE submissions are with very similar segmentation scores across various test datasets. In this approach, the GMM-HMM is used to perform segmentation, and the DNN is to classify segments into chord labels.

There are three different DNN models under discussion: FCNN, DBN and BLSTM-RNN. The major takeaway from the experiment results is that the BLSTM-RNN implementation has the highest score in terms of versatility metrics, and has the greatest potential to handle both ordinary and long-tail chord in a well balanced way, while the FCNN and DBN both tend to over-fit on ordinary/popular/dominating chords.

\Hsection{Chapter~\ref{cp:endtoend}} puts forwards a BLSTM-RNN approach with even chance training scheme as a solution to LVACE. This approach belongs to the ``local feature extraction - global classification'' category. Specifically, frame-wise features are extracted using a set of classical transformations. These features are then segmented and classified at the same time by a BLSTM-RNN.

To cater to long-tail chords, an even chance training scheme is introduced. This scheme tries to give the network equal attention to each target category. Two versions of BLSTM-RNN, with and without the scheme, are compared. Results demonstrate that it has positive effect on more balanced performance, while sacrificing scores in large population chords is the major drawback.

%, which is very different from the original common ACE target styles (i.e., pop and rock) in terms of not only chord vocabulary, but also harmonic structures, instrumental rendering styles, and rhythm sessions. Specially, jazz is unique in the way of bass walking and foreground instrument improvisation/soloing.
\Hsection{Chapter~\ref{cp:jazz}} applies one of the LVACE approaches to jazz. Surprisingly, the preliminary experiment finds that the classical GMM-HMM segmentation still works very well in jazz. Together with the DNN segment-wise classification, the system annotates chords much better than the baseline approach, which performs segmentation and classification in a single pass. Note that this preliminary experiment is conducted using a test dataset of 7 pure jazz backings.

The jazz ACE system is then extended to become a chord-scale estimator. Concretely, a template-based scale tracking algorithm is implemented on top of the ACE system. Two jazz improvisation platforms are introduced and implemented, both using the idea of chord-scale for jazz soloing. Combined with the chord-scale estimator, these platforms can let musical novice users to easily improvise jazz at a certain level.

Finally, a note sequence generator is implemented through a trained Markov model. An auto jazz improviser can then be achieved by combining this with the chord-scale estimator. Preliminary demo tracks have shown great musical potential of this unified system.

\section{Future Directions} \label{sec:6-future}

% better ACE systems
% deeper ACE models?
% ground-truth subjectivity issues
% long-tail issues

Extrapolating from this thesis, the future directions of ACE, in a deep learning oriented point of view, should focus on at least the following three aspects/challenges:
\begin{itemize}
\item implement deeper models
\item embrace ground-truth subjectivity
\item improve accuracy on long-tail chords
\end{itemize}

\Hsection{Deeper Models}
The first aspect considers using a deeper model for sequence modeling. This is rather a challenge motivated by pure scientific interest than practical interest. Chapter~\ref{cp:endtoend} describes a BLSTM-RNN that models sequence transformation from notegram level to segmented chord labels level. But as we all know, the promise of deep learning is to extract useful features from raw input, and to learn better transformations than those manually engineered. Thus this challenge asks for a deep learning model in a truly ``end-to-end'' sense, that captures every transformation from waveform level all the way to chord sequence level. Such model might not outperform the state-of-the-art at the beginning, but might show some promising potentials to achieve the optimal performance when certain computation or data requirements are met.

\Hsection{Subjectivity Issue}
The second challenges are fundamental to all kinds of machine learning researches, and it is especially important in ACE research, since the human chord annotations sometimes may disagree a lot, especially in long-tail chords, as reviewed in Section~\ref{sec:2-subjectivity}. Some ACE authors hence doubt the necessity to estimate long-tail chords. Such opinion may have its merit under certain practical consideration, especially when someone is trying to build an ACE software for chord learning beginners. It is not justified under a more practical scenario, where people want more ``accurate'' chord annotations for busking, practicing and rehearsal, and it is definitely a fallacy in an academic perspective, especially when the ultimate goal of ACE is to facilitate a machine musicianship, as introduced in Section~\ref{sec:1-moti}.

Therefore the annotation subjectivity issue needs to be embraced, or resolved, rather than neglected or abandoned. This is a difficult topic that may demand a lot of work and intelligence from data science, statistics, and machine learning. One key observation is that human learns to annotate chords (including long-tail ones) not by multiple examples of the same pieces, but by reading and listening to a lot of different examples, regardless of the annotators. When a person reaches a certain level, s/he may be able to correct the wrong annotations. The more advanced s/he is, the more long-tail chords s/he is able to annotate, spot and correct.

But as emphasized in Section~\ref{sec:2-subjectivity}, this issue should not overrule another equally important issue: to build a machine that ``learns well''. A 100\% ``golden standard'' ground truth should not be a necessary premise for building any machine learning system. Should their be any chaos or noise, the research community can always regress to use annotations from one single annotator.

\Hsection{Long-tail Chords Accuracy}
The long-tail chords accuracy is always involved with subjectivity issue. But it should be noted that not all instances of all long-tail chord types are easily subjected to the subjectivity. Although currently there is not any statistics showing the exact relationship between them, musical experience told us that some long-tail chord instances are much easier to be recognized than others, thus they receive less disagreement among annotators.

This serves as a key argument for LVACE, despite the subjectivity issue has not come to a solution. On the other hand, this is also supported by a Turing test argument, that ACE needs to support a vocabulary that is used by human annotators in order to pass the test.

Both Chapter~\ref{cp:ghmm} and ~\ref{cp:endtoend} point to some possible directions towards building more long-tail friendly systems, by either leveraging LSTM-RNN architecture to model temporal relationship within chord regions, or using an even chance training scheme for all classes. All in all, the future ACE researches should on one hand gradually increase the vocabulary, and on the other hand improve the accuracy of every class.

% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------



 






